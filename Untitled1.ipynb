{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"database.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = datetime(1970, 1, 1)\n",
    "\n",
    "def mapdateTotime(x):\n",
    "    try:\n",
    "        dt = datetime.strptime(x, \"%m/%d/%Y\")\n",
    "    except ValueError:\n",
    "        dt = datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "    diff = dt - epoch\n",
    "    return diff.total_seconds()\n",
    "\n",
    "df.Date = df.Date.apply(mapdateTotime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.57680000e+08   1.92460000e+01   1.45616000e+02   1.31600000e+02]\n",
      " [ -1.57507200e+08   1.86300000e+00   1.27352000e+02   8.00000000e+01]\n",
      " [ -1.57420800e+08  -2.05790000e+01  -1.73972000e+02   2.00000000e+01]\n",
      " ..., \n",
      " [  1.48288320e+09   3.69179000e+01   1.40426200e+02   1.00000000e+01]\n",
      " [  1.48296960e+09  -9.02830000e+00   1.18663900e+02   7.90000000e+01]\n",
      " [  1.48305600e+09   3.73973000e+01   1.41410300e+02   1.19400000e+01]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sushanto/.local/lib/python3.5/site-packages/ipykernel_launcher.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"\n",
      "/home/sushanto/.local/lib/python3.5/site-packages/ipykernel_launcher.py:6: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df1 = df\n",
    "col1 = df1[['Date','Latitude','Longitude','Depth']]\n",
    "col2 = df1['Magnitude']\n",
    "#Convert to Numpy array\n",
    "InputX1 = col1.as_matrix()\n",
    "InputY1 = col2.as_matrix()\n",
    "print(InputX1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mininum values: [ -1.57680000e+08  -7.70800000e+01  -1.79997000e+02  -1.10000000e+00]\n",
      "Maximum values: [  1.48305600e+09   8.60050000e+01   1.79998000e+02   7.00000000e+02]\n"
     ]
    }
   ],
   "source": [
    "X1_min = np.amin(InputX1,0)     \n",
    "X1_max = np.amax(InputX1,0)   \n",
    "print(\"Mininum values:\",X1_min)\n",
    "print(\"Maximum values:\",X1_max)\n",
    "Y1_min = np.amin(InputY1)     \n",
    "Y1_max = np.amax(InputY1) \n",
    "InputX1_norm = (InputX1-X1_min)/(X1_max-X1_min)\n",
    "InputY1_norm = InputY1  #No normalization in output\n",
    "\n",
    "#Reshape\n",
    "Xfeatures = 3 #Number of input features\n",
    "Yfeatures = 1 #Number of input features\n",
    "samples = 23000 # Number of samples\n",
    "\n",
    "InputX1_reshape = np.resize(InputX1_norm,(samples,Xfeatures))\n",
    "InputY1_reshape = np.resize(InputY1_norm,(samples,Yfeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2000\n",
    "InputX1train = InputX1_reshape[0:batch_size,:]\n",
    "InputY1train = InputY1_reshape[0:batch_size,:]\n",
    "#Validation data\n",
    "v_size = 2500\n",
    "InputX1v = InputX1_reshape[batch_size:batch_size+v_size,:]\n",
    "InputY1v = InputY1_reshape[batch_size:batch_size+v_size,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   5.90649048e-01,   9.04493118e-01],\n",
       "       [  1.89273998e-01,   1.05318589e-04,   4.84060459e-01],\n",
       "       [  8.53759080e-01,   1.15675367e-01,   1.57977883e-04],\n",
       "       ..., \n",
       "       [  5.83368992e-02,   9.84728805e-02,   4.72361039e-01],\n",
       "       [  8.41667245e-01,   1.98830409e-01,   9.85781991e-02],\n",
       "       [  5.33010393e-01,   8.49759024e-01,   8.00171160e-02]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InputX1train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_iterations = 1000\n",
    "display_iterations = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,shape=(None,Xfeatures))\n",
    "#Output\n",
    "Y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1 = 3\n",
    "L2 = 3\n",
    "L3 = 3\n",
    "\n",
    "#Layer1 weights\n",
    "W_fc1 = tf.Variable(tf.random_uniform([Xfeatures,L1]))\n",
    "b_fc1 = tf.Variable(tf.constant(0.1,shape=[L1]))\n",
    "\n",
    "#Layer2 weights\n",
    "W_fc2 = tf.Variable(tf.random_uniform([L1,L2]))\n",
    "b_fc2 = tf.Variable(tf.constant(0.1,shape=[L2]))\n",
    "\n",
    "#Layer3 weights\n",
    "W_fc3 = tf.Variable(tf.random_uniform([L2,L3]))\n",
    "b_fc3 = tf.Variable(tf.constant(0.1,shape=[L3]))\n",
    "\n",
    "#Output layer weights\n",
    "W_fO= tf.Variable(tf.random_uniform([L3,Yfeatures]))\n",
    "b_fO = tf.Variable(tf.constant(0.1,shape=[Yfeatures]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "matmul_fc1=tf.matmul(X, W_fc1) + b_fc1\n",
    "h_fc1 = tf.nn.relu(matmul_fc1)   #ReLU activation\n",
    "#Layer 2\n",
    "matmul_fc2=tf.matmul(h_fc1, W_fc2) + b_fc2\n",
    "h_fc2 = tf.nn.relu(matmul_fc2)   #ReLU activation\n",
    "#Layer 3\n",
    "matmul_fc3=tf.matmul(h_fc2, W_fc3) + b_fc3\n",
    "h_fc3 = tf.nn.relu(matmul_fc3)   #ReLU activation\n",
    "#Output layer\n",
    "matmul_fc4=tf.matmul(h_fc3, W_fO) + b_fO\n",
    "output_layer = matmul_fc4  #linear activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_square =  tf.reduce_mean(tf.square(Y-output_layer))\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(mean_square)\n",
    "\n",
    "#Operation to save variables\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: [11.045496]\n",
      "Training loss is: [10.870988] at itertion: 0\n",
      "Validation loss is: [9.4310589] at itertion: 0\n",
      "Training loss is: [2.1162767] at itertion: 200\n",
      "Validation loss is: [1.7558943] at itertion: 200\n",
      "Training loss is: [1.0439968] at itertion: 400\n",
      "Validation loss is: [0.93638349] at itertion: 400\n",
      "Training loss is: [0.5834136] at itertion: 600\n",
      "Validation loss is: [0.56576037] at itertion: 600\n",
      "Training loss is: [0.37445411] at itertion: 800\n",
      "Validation loss is: [0.38150245] at itertion: 800\n",
      "Model saved in file: /tmp/earthquake_model.ckpt\n",
      "Final training loss: [0.27514073]\n",
      "Final validation loss: [0.2841925]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(\"Training loss:\",sess.run([mean_square],feed_dict={X:InputX1train,Y:InputY1train}))\n",
    "    for i in range(training_iterations):\n",
    "        sess.run([train_step],feed_dict={X:InputX1train,Y:InputY1train})\n",
    "        if i%display_iterations ==0:\n",
    "            print(\"Training loss is:\",sess.run([mean_square],feed_dict={X:InputX1train,Y:InputY1train}),\"at itertion:\",i)\n",
    "            print(\"Validation loss is:\",sess.run([mean_square],feed_dict={X:InputX1v,Y:InputY1v}),\"at itertion:\",i)\n",
    "    # Save the variables to disk.\n",
    "    save_path = saver.save(sess, \"/tmp/earthquake_model.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "    print(\"Final training loss:\",sess.run([mean_square],feed_dict={X:InputX1train,Y:InputY1train}))\n",
    "    print(\"Final validation loss:\",sess.run([mean_square],feed_dict={X:InputX1v,Y:InputY1v}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: [26.554937]\n",
      "Training loss is: [26.423117] at itertion: 0\n",
      "Validation loss is: [24.605909] at itertion: 0\n",
      "Training loss is: [1.4285828] at itertion: 200\n",
      "Validation loss is: [1.2090894] at itertion: 200\n",
      "Training loss is: [1.0857887] at itertion: 400\n",
      "Validation loss is: [1.029991] at itertion: 400\n",
      "Training loss is: [0.84440452] at itertion: 600\n",
      "Validation loss is: [0.82580078] at itertion: 600\n",
      "Training loss is: [0.65542573] at itertion: 800\n",
      "Validation loss is: [0.65780348] at itertion: 800\n",
      "Model saved in file: /tmp/earthquake_model.ckpt\n",
      "Final training loss: [0.51259726]\n",
      "Final validation loss: [0.52423543]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(\"Training loss:\",sess.run([mean_square],feed_dict={X:InputX1train,Y:InputY1train}))\n",
    "    for i in range(training_iterations):\n",
    "        sess.run([train_step],feed_dict={X:InputX1train,Y:InputY1train})\n",
    "        if i%display_iterations ==0:\n",
    "            print(\"Training loss is:\",sess.run([mean_square],feed_dict={X:InputX1train,Y:InputY1train}),\"at itertion:\",i)\n",
    "            print(\"Validation loss is:\",sess.run([mean_square],feed_dict={X:InputX1v,Y:InputY1v}),\"at itertion:\",i)\n",
    "    # Save the variables to disk.\n",
    "    save_path = saver.save(sess, \"/tmp/earthquake_model.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "    print(\"Final training loss:\",sess.run([mean_square],feed_dict={X:InputX1train,Y:InputY1train}))\n",
    "    print(\"Final validation loss:\",sess.run([mean_square],feed_dict={X:InputX1v,Y:InputY1v}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Latitude between -77 to 86:11.938\n",
      "Enter Longitude between -180 to 180:11.938\n",
      "Enter Depth between 0 to 700:30\n",
      "Enter the date (Month/Day/Year format):01/09/1965\n",
      "INFO:tensorflow:Restoring parameters from /tmp/earthquake_model.ckpt\n",
      "Model restored.\n",
      "output: [array([[ 6.04897165]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "lat = input(\"Enter Latitude between -77 to 86:\")\n",
    "long = input(\"Enter Longitude between -180 to 180:\")\n",
    "depth = input(\"Enter Depth between 0 to 700:\")\n",
    "date = input(\"Enter the date (Month/Day/Year format):\")\n",
    "InputX2 = np.asarray([[lat,long,depth,mapdateTotime(date)]],dtype=np.float32)\n",
    "InputX2_norm = (InputX2-X1_min)/(X1_max-X1_min)\n",
    "InputX1test = np.resize(InputX2_norm,(1,Xfeatures))\n",
    "with tf.Session() as sess:\n",
    "    # Restore variables from disk for validation.\n",
    "    saver.restore(sess, \"/tmp/earthquake_model.ckpt\")\n",
    "    print(\"Model restored.\")\n",
    "    #print(\"Final validation loss:\",sess.run([mean_square],feed_dict={X:InputX1v,Y:InputY1v}))\n",
    "    print(\"output:\",sess.run([output_layer],feed_dict={X:InputX1test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Type</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Depth Error</th>\n",
       "      <th>Depth Seismic Stations</th>\n",
       "      <th>Magnitude</th>\n",
       "      <th>Magnitude Type</th>\n",
       "      <th>...</th>\n",
       "      <th>Magnitude Seismic Stations</th>\n",
       "      <th>Azimuthal Gap</th>\n",
       "      <th>Horizontal Distance</th>\n",
       "      <th>Horizontal Error</th>\n",
       "      <th>Root Mean Square</th>\n",
       "      <th>ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Location Source</th>\n",
       "      <th>Magnitude Source</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-157680000.0</td>\n",
       "      <td>13:44:18</td>\n",
       "      <td>19.246</td>\n",
       "      <td>145.616</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>131.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MW</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ISCGEM860706</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>Automatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-157507200.0</td>\n",
       "      <td>11:29:49</td>\n",
       "      <td>1.863</td>\n",
       "      <td>127.352</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.8</td>\n",
       "      <td>MW</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ISCGEM860737</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>Automatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-157420800.0</td>\n",
       "      <td>18:05:58</td>\n",
       "      <td>-20.579</td>\n",
       "      <td>-173.972</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.2</td>\n",
       "      <td>MW</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ISCGEM860762</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>Automatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-157161600.0</td>\n",
       "      <td>18:49:43</td>\n",
       "      <td>-59.076</td>\n",
       "      <td>-23.557</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.8</td>\n",
       "      <td>MW</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ISCGEM860856</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>Automatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-157075200.0</td>\n",
       "      <td>13:32:50</td>\n",
       "      <td>11.938</td>\n",
       "      <td>126.427</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.8</td>\n",
       "      <td>MW</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ISCGEM860890</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>ISCGEM</td>\n",
       "      <td>Automatic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date      Time  Latitude  Longitude        Type  Depth  Depth Error  \\\n",
       "0 -157680000.0  13:44:18    19.246    145.616  Earthquake  131.6          NaN   \n",
       "1 -157507200.0  11:29:49     1.863    127.352  Earthquake   80.0          NaN   \n",
       "2 -157420800.0  18:05:58   -20.579   -173.972  Earthquake   20.0          NaN   \n",
       "3 -157161600.0  18:49:43   -59.076    -23.557  Earthquake   15.0          NaN   \n",
       "4 -157075200.0  13:32:50    11.938    126.427  Earthquake   15.0          NaN   \n",
       "\n",
       "   Depth Seismic Stations  Magnitude Magnitude Type    ...      \\\n",
       "0                     NaN        6.0             MW    ...       \n",
       "1                     NaN        5.8             MW    ...       \n",
       "2                     NaN        6.2             MW    ...       \n",
       "3                     NaN        5.8             MW    ...       \n",
       "4                     NaN        5.8             MW    ...       \n",
       "\n",
       "   Magnitude Seismic Stations  Azimuthal Gap  Horizontal Distance  \\\n",
       "0                         NaN            NaN                  NaN   \n",
       "1                         NaN            NaN                  NaN   \n",
       "2                         NaN            NaN                  NaN   \n",
       "3                         NaN            NaN                  NaN   \n",
       "4                         NaN            NaN                  NaN   \n",
       "\n",
       "   Horizontal Error  Root Mean Square            ID  Source Location Source  \\\n",
       "0               NaN               NaN  ISCGEM860706  ISCGEM          ISCGEM   \n",
       "1               NaN               NaN  ISCGEM860737  ISCGEM          ISCGEM   \n",
       "2               NaN               NaN  ISCGEM860762  ISCGEM          ISCGEM   \n",
       "3               NaN               NaN  ISCGEM860856  ISCGEM          ISCGEM   \n",
       "4               NaN               NaN  ISCGEM860890  ISCGEM          ISCGEM   \n",
       "\n",
       "  Magnitude Source     Status  \n",
       "0           ISCGEM  Automatic  \n",
       "1           ISCGEM  Automatic  \n",
       "2           ISCGEM  Automatic  \n",
       "3           ISCGEM  Automatic  \n",
       "4           ISCGEM  Automatic  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Latitude between -77 to 86:18.584\n",
      "Enter Longitude between -180 to 180:-99.389\n",
      "Enter Depth between 0 to 700:50\n",
      "Enter the date (Month/Day/Year format):9/19/2017\n",
      "INFO:tensorflow:Restoring parameters from /tmp/earthquake_model.ckpt\n",
      "Model restored.\n",
      "output: [array([[ 5.77525187]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "lat = input(\"Enter Latitude between -77 to 86:\")\n",
    "long = input(\"Enter Longitude between -180 to 180:\")\n",
    "depth = input(\"Enter Depth between 0 to 700:\")\n",
    "date = input(\"Enter the date (Month/Day/Year format):\")\n",
    "InputX2 = np.asarray([[lat,long,depth,mapdateTotime(date)]],dtype=np.float32)\n",
    "InputX2_norm = (InputX2-X1_min)/(X1_max-X1_min)\n",
    "InputX1test = np.resize(InputX2_norm,(1,Xfeatures))\n",
    "with tf.Session() as sess:\n",
    "    # Restore variables from disk for validation.\n",
    "    saver.restore(sess, \"/tmp/earthquake_model.ckpt\")\n",
    "    print(\"Model restored.\")\n",
    "    #print(\"Final validation loss:\",sess.run([mean_square],feed_dict={X:InputX1v,Y:InputY1v}))\n",
    "    print(\"output:\",sess.run([output_layer],feed_dict={X:InputX1test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
